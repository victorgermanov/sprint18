{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1098ffeb",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0253490",
   "metadata": {},
   "source": [
    "1  Цели соревнования\n",
    "\n",
    "На основе данных, предоставленных устроителями соревнования, разработать и выбрать лучшие модели машинного обучения. На основе моделей машинного обучения разработать решение, которое позволит предсказать закрытие стартапа.\n",
    "\n",
    "2  Ход Исследования\n",
    "1. Базу данных по стартапам я соберу из двух источников: файл 'kaggle_startups_train_27042024.csv' с обучающими данными по стартапам и файл 'kaggle_startups_test_27042024.csv' с данными по стартапам, закрытие которых необходимо предсказать. \n",
    "2. С данными я не знаком. Поэтому мне понадобится обзор данных. \n",
    "3. Я проверю таблицы на пропуски и дублирование, внесу исправления, не влияющие на общую целостность и качество анализа, добавлю необходимые столбцы и проведу исследовательский и корреляционный анализ. \n",
    "4. Для построения модели я использую технологию пайплайна. \n",
    "5. Для иследования важности входных признаков я использую SHAP-анализ. \n",
    "\n",
    "3  Этапы исследования:\n",
    "\n",
    "3.1. Загрузка и ознакомление с данными,\n",
    "3.2. Педварительная обработка,\n",
    "3.3. Исследовательский анализ данных,\n",
    "3.4. Разработка новых синтетических признаков,\n",
    "3.5. Проверка на мультиколлинеарность,\n",
    "3.6. Отбор финального набора обучающих признаков,\n",
    "3.7. Выбор и обучение моделей,\n",
    "3.8. Получение результат,\n",
    "3.9. Анализ важности ее признаков,\n",
    "\n",
    "4 Дополнительные задания:\n",
    "\n",
    "4.1. Реализовать решение с использованием технологии pipeline (из библиотеки sklearn, imblearn),\n",
    "4.2. Выполнить полноценный исследовательский анализ и сформулировать рекомендации позволяющие повысить шанс на успех стартапа.\n",
    "4.3. Подготовить полноценный отчет по исследовательской работе Дата Сайнтиста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b51688d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установим актуальную версию модуля sklearn\n",
    "!pip install --upgrade scikit-learn==1.4.1.post1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4b5400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорт библиотек\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import stats as st\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "!pip install phik -q\n",
    "import phik                                                     # инструмент корреляционного анализ\n",
    "\n",
    "!pip install shap -q\n",
    "import shap                                                     # обеспечивает SHAP-анализ важности признаков\n",
    "\n",
    "!pip install -U imbalanced-learn -quit  \n",
    "from imblearn.over_sampling import SMOTE                        # инструмент сэмплирования данных\n",
    "\n",
    "from scipy.stats import shapiro                                 # проверка гауссовского распределенеия\n",
    "from scipy.stats import normaltest                              # проверка гауссовского распределенеия\n",
    "\n",
    "from sklearn.model_selection import train_test_split            # селектор тренировочной и тестовой выборок\n",
    "from sklearn.impute import SimpleImputer                        # класс для работы с пропусками\n",
    "from sklearn.preprocessing import (                             # классы для преобразования данных\n",
    "    QuantileTransformer,\n",
    "    PowerTransformer,\n",
    "    OneHotEncoder, \n",
    "    OrdinalEncoder,\n",
    "    LabelEncoder,\n",
    "    StandardScaler,\n",
    "    MinMaxScaler,\n",
    "    RobustScaler,\n",
    "    PolynomialFeatures\n",
    ")\n",
    "\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier             # модель «Рандомный лес»\n",
    "from sklearn.neighbors import KNeighborsClassifier              # модель kNN\n",
    "from sklearn.linear_model import LogisticRegression             # модель логистической регрессии\n",
    "\n",
    "from sklearn.pipeline import Pipeline                           # обеспечивает работу с пайплайнами\n",
    "from sklearn.compose import ColumnTransformer                   # помогает работать с данными разного типа в одном наборе\n",
    "from sklearn.model_selection import GridSearchCV                # инструмент для автоподбора гиперпараметров\n",
    "from sklearn.model_selection import RandomizedSearchCV          # инструмент для автоподбора гиперпараметров\n",
    "\n",
    "from sklearn.metrics import f1_score                            # метрики\n",
    "from sklearn.metrics import make_scorer                         # инструмент создания метрик\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format               # настройка формата вывода чисел\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc84953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция отмечает значением True строки с проблемными (дубликатными) названиями стартапов\n",
    "def names_function(x):\n",
    "    if type(x) != type(''):        \n",
    "        return False\n",
    "    for bname in names:\n",
    "        if bname == x.lower():\n",
    "            return True\n",
    "    return False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edfca5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция проверки гауссовского распределения \n",
    "def check_stats(x):\n",
    "    stat, p = shapiro(x)\n",
    "    print('Распределение', x.name, 'shapiro p =', round(p, 3), '-', 'скорее гауссовское' if p > 0.05 else 'скорее не гауссовское')\n",
    "    stat, p = normaltest(x)\n",
    "    print('Распределение', x.name, 'normaltest p =', round(p,  3), '-', 'скорее гауссовское' if p > 0.05 else 'скорее не гауссовское')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abfccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция отрисовки диаграммы типа 'histplot' и диаграммы размаха. Аргументы: датасет, наименование столбца.\n",
    "def plot_function_col(df, column):    \n",
    "    plt.figure(figsize=[14, 5])\n",
    "    plt.subplot(2, 1, 1) \n",
    "    sns.set(rc={\"figure.figsize\":(18, 5)})\n",
    "    sns.histplot(data=df, x=column, bins=5000).set(title='Гистограмма и диаграмма размаха по признаку ' + column)    \n",
    "    plt.subplot(2, 1, 2)    \n",
    "    sns.boxplot(x=df[column]).set()  \n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d361a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция отрисовки диаграммы типа 'bar'. Аргументы: набор данных, заголовок, текст ylabel\n",
    "def bar_function(seria, title, ylabel):\n",
    "    feature = seria\n",
    "    h_feature = feature.plot(kind='bar', figsize=(10, 5), grid=True)\n",
    "    h_feature.set_title(title)\n",
    "    h_feature.set_xlabel('Категории')\n",
    "    h_feature.set_ylabel(ylabel)\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3050aeb5",
   "metadata": {},
   "source": [
    "Шаг 1. Загрузка и ознакомление с данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff7c287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим обучающую базу данных\n",
    "df_1 = pd.read_csv('kaggle_startups_train_27042024.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90270902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выведем на экран\n",
    "df_1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f35e1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим информацию\n",
    "df_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99038a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построим гистограммы численных столбцов для предварительного знакомства с характером данных\n",
    "df_1.hist(bins=45, figsize=(10, 3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892faeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отследим столбцы с пропусками\n",
    "for column in df_1.columns:    \n",
    "    print(f'Столбец \"{column}\" имеет {52514 - df_1[column].count()} пропусков')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48b246c",
   "metadata": {},
   "source": [
    "Пояснения к обучающей базе данных:\n",
    "\n",
    "1. Таблица имеет 52514 записей, размещенных в 13 столбцах.\n",
    "3. На гистограмме заметно, что столбец \"funding_total_usd\" имеет сильный выброс\n",
    "2. Столбец \"name\" имеет 1 пропусков\n",
    "3. Столбец \"category_list\" имеет 2465 пропусков\n",
    "4. Столбец \"funding_total_usd\" имеет 10069 пропусков\n",
    "5. Столбец \"country_code\" имеет 5501 пропусков\n",
    "6. Столбец \"state_code\" имеет 6762 пропусков\n",
    "7. Столбец \"region\" имеет 6358 пропусков\n",
    "8. Столбец \"city\" имеет 6358 пропусков\n",
    "9. Столбец \"closed_at\" имеет 47599 пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c41ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим базу данных для предсказаний\n",
    "df_2 = pd.read_csv('kaggle_startups_test_27042024.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ddee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выведем на экран\n",
    "df_2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51674931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим информацию\n",
    "df_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47851ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построим гистограммы численных столбцов для предварительного знакомства с характером данных\n",
    "df_2.hist(bins=45, figsize=(10, 7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cf7c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отследим столбцы с пропусками\n",
    "for column in df_2.columns:    \n",
    "    print(f'Столбец \"{column}\" имеет {13125 - df_2[column].count()} пропусков')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf1b6ca",
   "metadata": {},
   "source": [
    "Пояснения к базе данных для предсказаний:\n",
    "\n",
    "1. Таблица имеет 13125 записей, размещенных в 12 столбцах.\n",
    "2. Столбец \"category_list\" имеет 591 пропусков\n",
    "3. Столбец \"funding_total_usd\" имеет 2578 пропусков\n",
    "4. Столбец \"country_code\" имеет 1382 пропусков\n",
    "5. Столбец \"state_code\" имеет 1695 пропусков\n",
    "6. Столбец \"region\" имеет 1589 пропусков\n",
    "7. Столбец \"city\" имеет 1587 пропусков"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4319da1f",
   "metadata": {},
   "source": [
    "Выводы по шагу \"Загрузка и ознакомление с данными\":\n",
    "\n",
    "1. Таблицы-источники имеют неодинаковые наборы столбцов. \n",
    "2. Обучающая база содержит столбец с целевым признаком и дополнительный столбец 'closed_at' для явного указания стартапов, закрытых до 2018-01-01.\n",
    "3. База данных для предсказаний содержит столбец 'lifetime'. отсутствующий в обучающей базе.\n",
    "4. После предварительной обработки таблиц необходимо привести в соответствие наборы их столбцов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7664a28",
   "metadata": {},
   "source": [
    "Шаг 2. Педварительная обработка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d3b341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пропуски в столбцах 'name', 'category_list', 'country_code', 'state_code', 'region', 'city' заменим зачением 'Unknown'\n",
    "columns = ['name', 'category_list', 'country_code', 'state_code', 'region', 'city']\n",
    "for col in columns:\n",
    "    df_1[col].fillna('Unknown', inplace = True)\n",
    "    df_2[col].fillna('Unknown', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6ddc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пропуски в столбце 'closed_at' df_1_1 заменим зачением '2018-01-01'\n",
    "const_date = pd.to_datetime('2018-01-01')\n",
    "df_1['closed_at'].fillna('2018-01-01', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9caefb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# В df_1 и df_2 переведем в формат даты столбцы 'founded_at', 'first_funding_at', 'last_funding_at', 'closed_at'\n",
    "df_1['founded_at'] = pd.to_datetime(df_1['founded_at'])\n",
    "df_1['first_funding_at'] = pd.to_datetime(df_1['first_funding_at'])\n",
    "df_1['last_funding_at'] = pd.to_datetime(df_1['last_funding_at'])\n",
    "df_1['closed_at'] = pd.to_datetime(df_1['closed_at'])\n",
    "df_2['founded_at'] = pd.to_datetime(df_2['founded_at'])\n",
    "df_2['first_funding_at'] = pd.to_datetime(df_2['first_funding_at'])\n",
    "df_2['last_funding_at'] = pd.to_datetime(df_2['last_funding_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b14850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Далее работаем с копиями таблиц-источников\n",
    "df_1_1 = df_1.copy(deep=True)\n",
    "df_2_1 = df_2.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2f01f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверим явные дубликаты в таблице df_1_1\n",
    "print('Явных дубликатов строк:', df_1_1.duplicated().sum())\n",
    "# Проверим явные дубликаты в таблице df_2_1\n",
    "print('Явных дубликатов строк:', df_2_1.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb8b20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B таблице df_1_1 проверим дубликаты по столбцу 'name'\n",
    "print('Явных дубликатов по столбцу name:', df_1_1.duplicated().sum())\n",
    "df_1_1['name'] = df_1_1['name'].str.lower()\n",
    "print('Подозрений на неявные дубликаты по столбцу name в df_1_1:', df_1_1['name'].duplicated().sum())\n",
    "# B таблице df_2_1 проверим дубликаты по столбцу 'name'\n",
    "print('Явных дубликатов по столбцу name:', df_2_1.duplicated().sum())\n",
    "df_2_1['name'] = df_2_1['name'].str.lower()\n",
    "print('Подозрений на неявные дубликаты по столбцу name в df_2_1:', df_2_1['name'].duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f7e0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выявим неявные дубликаты по столбцу 'name'\n",
    "value_counts_df_1_1 = df_1_1['name'].value_counts()\n",
    "value_counts_df_2_1 = df_2_1['name'].value_counts()\n",
    "# Преобразуем value_counts_df_1_1 в df и присвоим имена колонкам\n",
    "df_value_counts_df_1_1 = pd.DataFrame(value_counts_df_1_1)\n",
    "df_value_counts_df_1_1 = df_value_counts_df_1_1.reset_index()\n",
    "df_value_counts_df_1_1.columns = ['unique_values', 'counts']\n",
    "print(df_value_counts_df_1_1)\n",
    "# Преобразуем value_counts_df_2_1 в df и присвоим имена колонкам\n",
    "df_value_counts_df_2_1 = pd.DataFrame(value_counts_df_2_1)\n",
    "df_value_counts_df_2_1 = df_value_counts_df_2_1.reset_index()\n",
    "df_value_counts_df_2_1.columns = ['unique_values', 'counts']\n",
    "print(df_value_counts_df_2_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f908d023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавим в df_1_1 столбец для True-обозначения неявных дубликатов по столбцу 'name' и посчитаем их количество\n",
    "names = df_value_counts_df_1_1['unique_values'].head(43)\n",
    "df_1_1['dupl_name'] = df_1_1['name'].apply(names_function)\n",
    "df_1_1['dupl_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66d8462",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Выведем на экран записи df_1_1 с неявными дубликатами по столбцу 'name'\n",
    "df_1_1d = df_1_1[df_1_1['dupl_name'] == True]\n",
    "print('Подозрение на неявняе дубликаты в df_1_1:')\n",
    "print(df_1_1d.sort_values('name').head(4))\n",
    "# Выведем на экран записи df_2_1 с неявными дубликатами в столбце 'name'\n",
    "print()\n",
    "print('Подозрение на неявняе дубликаты в df_2_1:')\n",
    "selected = df_2_1.loc[(df_2_1['name'] == 'quip') | (df_2_1['name'] == 'spoke')].sort_values('name')\n",
    "print(selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53328bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удалим единственный неявный дубликат в базе df_1_1\n",
    "df_1_1 = df_1_1.drop(index=3250)\n",
    "df_1_1 = df_1_1.reset_index(drop=True)\n",
    "df_1_1 = df_1_1.drop('dupl_name', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0623b077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверим изменения в таблицах\n",
    "df_1_1.info()\n",
    "print()\n",
    "df_2_1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1838ab17",
   "metadata": {},
   "source": [
    "Пояснения по столбцу 'name' обучающей базы данных:\n",
    "\n",
    "1. Явных дубликатов по столбцу name: 0\n",
    "2. Подозрений на неявные дубликаты по столбцу name: 43\n",
    "3. Визуальная проверка строк с дублированными названиями стартапов показал, что неявным дупликатом является только строка под индексом 3250, так как там полностью совпадают дата создания и местоположение стартапа. Строка удалена.\n",
    "4. В остальных строках эти значения не совпадают - то есть это не дубликаты."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8082d0f8",
   "metadata": {},
   "source": [
    "Пояснения по столбцу 'name' базы данных для предсказаний:\n",
    "\n",
    "1. Явных дубликатов по столбцу name: 0\n",
    "2. Подозрений на неявные дубликаты по столбцу name: 2\n",
    "3. Визуальная проверка строк с дублированными названиями стартапов показал, что значения столбцов в строках не совпадают, то есть неявные дубликаты остутствуют."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d485abdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пропуски в столбце 'funding_total_usd' заменим медианным зачением\n",
    "df_1_1['funding_total_usd'].fillna(df_1_1['funding_total_usd'].median(), inplace = True)\n",
    "df_2_1['funding_total_usd'].fillna(df_2_1['funding_total_usd'].median(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0370d9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверим на выбросы и нормальность числовые столбцы таблицы df_1_1\n",
    "plot_function_col(df_1_1, 'funding_total_usd')\n",
    "check_stats(df_1_1['funding_total_usd'])\n",
    "plot_function_col(df_1_1, 'funding_rounds')\n",
    "check_stats(df_1_1['funding_rounds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a52cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим статистические сводки по столбцам 'funding_total_usd' и 'funding_rounds' в df_1_1\n",
    "df_1_1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32168ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Избавимся от выбросов в столбце 'funding_total_usd'. Разумным представляется предел финансирования 200 млн. USD \n",
    "df_1_1 = df_1_1.loc[df_1_1['funding_total_usd'] < 200000000]\n",
    "plot_function_col(df_1_1, 'funding_total_usd')\n",
    "check_stats(df_1_1['funding_total_usd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3167d447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавим в df_1_1 столбец 'lifetime' - время жизни стартапа\n",
    "df_1_1['lifetime'] = (df_1_1['closed_at'] - df_1_1['founded_at']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6d1a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавим в df_1_1 столбец 'post_days' - количество дней с закрытия стартапа\n",
    "df_1_1['post_days'] = (const_date - df_1_1['closed_at']).dt.days\n",
    "# Добавим в df_2_1 столбец 'post_days' - количество дней с закрытия стартапа\n",
    "df_2_1['post_days'] = (const_date - df_2_1['founded_at']).dt.days - df_2_1['lifetime']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b4fee1",
   "metadata": {},
   "source": [
    "Выводы по шагу 'Педварительная обработка'\n",
    "\n",
    "1. В категориальных столбцах обеих таблиц пропуски заменены значением 'Unknown'. Это сделано чтобы в обучении участвовало как можно больше записей.\n",
    "2. В солбце 'funding_total_usd' пропуски заменены медианными значениями.\n",
    "3. В df_1_1 удалены записи с выбросами по солбцу 'funding_total_usd'. Предел финансирования выбран в 200 млн. USD.\n",
    "4. Числовые значения в столбце 'funding_rounds' по сути являются категориальными значениями. Там аномальных значений не обнаружено.\n",
    "5. После предварительной обработки таблица df_1_1 содержит 52016 записей, таблица df_2_1 содержит 13125 записей.\n",
    "6. Для соответствия с df_2_1 в таблицу df_1_1 добавлен столбец 'lifetime'.\n",
    "7. В обе таблицы добавлен столбец 'post_days' - количество дней с закрытия стартапа."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea2b41f",
   "metadata": {},
   "source": [
    "Шаг 3. Исследовательский анализ данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd5ae54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сбросим индексы в df_1_1\n",
    "df_1_1 = df_1_1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63262133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверим изменения в таблице\n",
    "df_1_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b039ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Значения по столбцу 'name' являются идентификаторами стартапов и не влияют на целевой признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfa52b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Данные по столбцу 'category_list' содержат очень много категорий стартапов, описаны разнообразно и нестандартизованно.\n",
    "# Для исследования их необходимо свести в несколько крупных категорий по прикладным областям: искусство, политика, \n",
    "# торговля, производство, услуги, транспорт, медицина, образование, СМИ, общепит, айти-технологии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637bc1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Исследуем процент закрытых стартапов в логарифмической зависимости от величины финансирования\n",
    "df_1_1['funding_total_log'] = np.log2(df_1_1['funding_total_usd'])\n",
    "df_2_1['funding_total_log'] = np.log2(df_2_1['funding_total_usd'])\n",
    "df_1_1['funding_total_log'].describe()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2b1de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция разделяет стартапы по столбцу 'funding_total_log'\n",
    "def funding_log(x):\n",
    "    n = 30\n",
    "    closed_counts = [0] * n\n",
    "    operating_counts = [0] * n\n",
    "    closed_percent = [0] * n\n",
    "    for i in range(0, 52016):\n",
    "        for j in range(1, n):\n",
    "            if x.loc[i,'funding_total_log'] < j:            \n",
    "                if x.loc[i,'status'] == 'closed':\n",
    "                    closed_counts[j] += 1\n",
    "                if x.loc[i,'status'] == 'operating':\n",
    "                    operating_counts[j] += 1\n",
    "                break\n",
    "    for p in range(0, n):\n",
    "        try:\n",
    "            closed_percent[p] = round(closed_counts[p] / (closed_counts[p] + operating_counts[p]) * 100, 2)\n",
    "        except:\n",
    "            closed_percent[p] = 0 \n",
    "    return operating_counts, closed_counts, closed_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e02af5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Распределим стартапы по бинсам столбца 'funding_total_log'\n",
    "result_counts = funding_log(df_1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197f8a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим диаграмму распределения действующих и закрытых стартапов по bins столбца 'funding_total_log'\n",
    "y = pd.Series(result_counts[0]) \n",
    "bar_function(y, 'Действующие стартапы по категориям финансирования', 'Количество')\n",
    "y = pd.Series(result_counts[1]) \n",
    "bar_function(y, 'Закрытые стартапы по категориям финансирования', 'Количество')\n",
    "y = pd.Series(result_counts[2]) \n",
    "bar_function(y,  'Процент закрытых стартапов по категориям финансирования', 'Проценты')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed69e8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_1['funding_total_log'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c87331",
   "metadata": {},
   "source": [
    "Пояснения:\n",
    "\n",
    "1. Чтобы учесть логарифмическое распределение сумм финансирования, данные по столбцу обращены в логарифмы и распределны по линейным категориям в 30 бинсах.\n",
    "2. Гистограмма распределения долей закрытых стартапов показывает, что закрытые статапы в наибольшей доле финансировались на суммы менее 100000 долларов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afe62d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Исследуем распределение стартапов по странам в df_1_1\n",
    "country_counts = pd.DataFrame()\n",
    "country_counts['count_all'] = df_1_1.groupby(['country_code'])['status'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9999390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Соберем количество действующих и закрытых стартапов по странам\n",
    "df_1_1_closed = df_1_1.query('status == \"closed\"')\n",
    "df_1_1_operating = df_1_1.query('status == \"operating\"')\n",
    "country_counts['count_closed'] =  df_1_1_closed.groupby('country_code')['status'].count()\n",
    "country_counts['count_operating'] =  df_1_1_operating.groupby('country_code')['status'].count()\n",
    "country_counts.fillna(0, inplace = True)\n",
    "country_counts['ratio_closed'] = round(country_counts['count_closed'] / country_counts['count_all'] * 100, 2)\n",
    "top_country_counts = country_counts.sort_values(by='ratio_closed', ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b7c4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция отрисовки диаграммы типа 'bar'. Аргументы: набор данных, заголовок, текст ylabel\n",
    "def bar_function_2(y, title, ylabel):\n",
    "    feature = y\n",
    "    h_feature = feature.plot(kind='bar', figsize=(10, 3), grid=True)\n",
    "    h_feature.set_title(title)\n",
    "    h_feature.set_xlabel('Коды стран')\n",
    "    h_feature.set_ylabel(ylabel)\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12e0366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим диаграмму распределения стартапов по странам\n",
    "country_counts = country_counts.head(50)\n",
    "bar_function_2(top_country_counts['count_all'], 'Распределение стартапов по странам', 'Количество')\n",
    "country_counts = country_counts.head(50)\n",
    "bar_function_2(top_country_counts['count_closed'], 'Распределение закрытых стартапов по странам', 'Количество')\n",
    "country_counts = country_counts.head(50)\n",
    "bar_function_2(top_country_counts['ratio_closed'], 'Распределение процента закрытых стартапов по странам', 'Проценты')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb32af1",
   "metadata": {},
   "source": [
    "Пояснения:\n",
    "\n",
    "1. Распределение доли закрытых стартапов показывает, что за рассматриваемый период чаще всего стартапы закрывались в странах  третьего мира типа Сомали, Майотта, Грузии, Пуэрто-Рико и в России."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2043ed8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Исследуем распределения стартапов по количеству раундов финансирования в df_1_1\n",
    "round_counts = pd.DataFrame()\n",
    "round_counts['all'] = df_1_1.groupby(['funding_rounds'])['status'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf52ea89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Соберем количество действующих и закрытых стартапов по количеству раундов финансирования\n",
    "round_counts['closed'] =  df_1_1_closed.groupby('funding_rounds')['status'].count()\n",
    "round_counts['operate'] =  df_1_1_operating.groupby('funding_rounds')['status'].count()\n",
    "round_counts.fillna(0, inplace = True)\n",
    "round_counts['ratio_closed'] = round(round_counts['closed'] / round_counts['all'] * 100, 2)\n",
    "round_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c263d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим диаграмму распределения стартапов по количеству раундов финансирования\n",
    "bar_function_2(round_counts['all'], 'Распределение стартапов по раундам финансирования', 'Количество')\n",
    "bar_function_2(round_counts['closed'], 'Распределение стартапов по раундам финансирования', 'Количество')\n",
    "bar_function_2(round_counts['ratio_closed'], 'Распределение процента закрытых стартапов по раундам финансирования', 'Проценты')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b3583e",
   "metadata": {},
   "source": [
    "Пояснения:\n",
    "\n",
    "1. Распределение доли закрытых стартапов показывает, что за рассматриваемый период закрытые стартапы чаще всего имели не более одного раунда финансирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5473b325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# В df_1_1 и df_2_1 место дат финансирования проставим промежутки в днях\n",
    "df_1_1['first_funding_gap'] = abs(df_1_1['first_funding_at'] - df_1_1['founded_at']).dt.days\n",
    "df_1_1['last_funding_gap'] = abs(df_1_1['last_funding_at'] - df_1_1['first_funding_at']).dt.days\n",
    "df_2_1['first_funding_gap'] = abs(df_2_1['first_funding_at'] - df_2_1['founded_at']).dt.days\n",
    "df_2_1['last_funding_gap'] = abs(df_2_1['last_funding_at'] - df_2_1['first_funding_at']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d673e98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверим изменения в таблицах\n",
    "df_1_1.info()\n",
    "print()\n",
    "df_2_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322dde7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим информацию по столбцу 'lifetime'\n",
    "df_1_1['lifetime'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1152079a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция распределяет стартапы на категории по столбцу 'lifetime'\n",
    "def lifetime(x):\n",
    "    n = 30\n",
    "    closed_counts = [0] * n\n",
    "    operating_counts = [0] * n\n",
    "    closed_percent = [0] * n\n",
    "    for i in range(0, 52016):\n",
    "        for j in range(1, n):\n",
    "            if x.loc[i,'lifetime'] < j * 600:            \n",
    "                if x.loc[i,'status'] == 'closed':\n",
    "                    closed_counts[j] += 1\n",
    "                if x.loc[i,'status'] == 'operating':\n",
    "                    operating_counts[j] += 1\n",
    "                break\n",
    "    for p in range(0, n):\n",
    "        try:\n",
    "            closed_percent[p] = round(closed_counts[p] / (closed_counts[p] + operating_counts[p]) * 100, 2)\n",
    "        except:\n",
    "            closed_percent[p] = 0 \n",
    "    return operating_counts, closed_counts, closed_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19e89aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Распределим стартапы на категории по бинсам столбца 'lifetime'\n",
    "result_lifetime = lifetime(df_1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365c6a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим диаграмму распределения действующих стартапов по bins столбца 'lifetime'\n",
    "y = pd.Series(result_lifetime[0]) \n",
    "bar_function(y, 'Действующие стартапы по bins столбца lifetime', 'Количество')\n",
    "\n",
    "# Посмотрим диаграмму распределения действующих стартапов по bins столбца 'lifetime'\n",
    "y = pd.Series(result_lifetime[1]) \n",
    "bar_function(y, 'Закрытые стартапы по bins столбца lifetime', 'Количество')\n",
    "\n",
    "# Посмотрим диаграмму распределения действующих стартапов по bins столбца 'lifetime'\n",
    "y = pd.Series(result_lifetime[2]) \n",
    "bar_function(y, 'Процент закрытых стартапов по bins столбца lifetime', 'Процент')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73fe400",
   "metadata": {},
   "source": [
    "Пояснения:\n",
    "\n",
    "1. Распределение доли закрытых стартапов показывает, что за рассматриваемый период закрытые стартапы чаще всего имели время жизни не более трех лет."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bd51bc",
   "metadata": {},
   "source": [
    "Выводы по шагу \"Исследовательский анализ данных\":\n",
    "\n",
    "1. Чтобы учесть логарифмическое характер распределения сумм финансирования стартапов, данные по столбцу обращены в логарифмы и распределены по линейным категориям в 30 бинсах.\n",
    "2. Построены диаграммы распределения действующих и закрытых стартапов, а также диаграммы распределения долей закрытых стартапов в зависимости от различных факторов. Они показывают, что:\n",
    "3. Закрытые статапы в наибольшей доле финансировались на суммы менее 100000 долларов.\n",
    "4. За рассматриваемый период чаще всего стартапы закрывались в странах третьего мира типа Сомали, Майотта, Грузии, Пуэрто-Рико и в России.\n",
    "5. Закрытые стартапы чаще всего имели не более одного раунда финансирования.\n",
    "5. Закрытые стартапы чаще всего имели время жизни не более трех лет."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebaddf50",
   "metadata": {},
   "source": [
    "Шаг 4. Разработка новых синтетических признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790a81f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_1.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543bcf9b",
   "metadata": {},
   "source": [
    "Новый признак 'category_funding_log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426b2322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим описания столбца 'funding_total_log' в df_1_1 и df_2_1\n",
    "print('funding_total_log df_1_1:')\n",
    "print(df_1_1['funding_total_log'].describe())\n",
    "print()\n",
    "print('funding_total_log df_2_1:')\n",
    "print(df_2_1['funding_total_log'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77e19f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция распределяет стартапы на категории 'category_funding_log' (30)\n",
    "def funding_category_func(x):\n",
    "    for i in range(1, 3):\n",
    "        if x > i * 10 - 10 and x < i * 10:            \n",
    "            return i\n",
    "    return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d08d3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Закодируем стартапы в df_1_1 и df_2_1 по категориям 'funding_total_log'\n",
    "df_1_1['category_funding_log'] = df_1_1['funding_total_log'].apply(funding_category_func)\n",
    "df_2_1['category_funding_log'] = df_2_1['funding_total_log'].apply(funding_category_func)\n",
    "df_1_1.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c180bbd",
   "metadata": {},
   "source": [
    "Новый признак 'category_lifetime'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc34fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим описания столбца 'lifetime' в df_1_1 и df_2_1\n",
    "print('lifetime df_1_1:')\n",
    "print(df_1_1['lifetime'].describe())\n",
    "print()\n",
    "print('lifetime df_2_1:')\n",
    "print(df_2_1['lifetime'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3d773a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция перевода дней по столбцу 'lifetime' в категории (30)\n",
    "def category_lifetime_func(x):\n",
    "    for i in range(500, 17500, 500):\n",
    "        if x < i:            \n",
    "            return round(i / 500)\n",
    "    return 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f871fdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Переведем дни по столбцу 'lifetime' в категории\n",
    "df_1_1['category_lifetime'] = df_1_1['lifetime'].apply(category_lifetime_func)\n",
    "df_2_1['category_lifetime'] = df_2_1['lifetime'].apply(category_lifetime_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8819a9",
   "metadata": {},
   "source": [
    "Новый признак 'category_location'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89356d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def location_func(x):\n",
    "    if x == 'RUS':\n",
    "        return 1\n",
    "    elif x == 'USA':\n",
    "        return 2\n",
    "    else:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378f0a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Распределим стартапы по категориям стран локации\n",
    "df_1_1['category_location'] = df_1_1['country_code'].apply(location_func)\n",
    "df_2_1['category_location'] = df_2_1['country_code'].apply(location_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d4c04d",
   "metadata": {},
   "source": [
    "Новый признак 'category_firstgap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770193cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим описания столбца 'first_funding_gap' в df_1_1 и df_2_1\n",
    "print('first_funding_gap df_1_1:')\n",
    "print(df_1_1['first_funding_gap'].describe())\n",
    "print()\n",
    "print('first_funding_gap df_2_1:')\n",
    "print(df_2_1['first_funding_gap'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17a46fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция перевода дней по столбцу 'first_funding_gap' в категории (45)\n",
    "def category_firstgap_func(x):\n",
    "    for i in range(0, 45):\n",
    "        if x > i * 365 and x < i * 365 + 365:            \n",
    "            return i\n",
    "    return 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a092142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Переведем дни по столбцу df_1_1 'first_funding_gap' в категории\n",
    "df_1_1['category_firstgap'] = df_1_1['first_funding_gap'].apply(category_firstgap_func)\n",
    "df_2_1['category_firstgap'] = df_2_1['first_funding_gap'].apply(category_firstgap_func)\n",
    "df_1_1.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ded91ab",
   "metadata": {},
   "source": [
    "Новый признак 'category_lastgap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173fcdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим описания столбца 'last_funding_gap' в df_1_1 и df_2_1\n",
    "print('last_funding_gap df_1_1:')\n",
    "print(df_1_1['last_funding_gap'].describe())\n",
    "print()\n",
    "print('last_funding_gap df_2_1:')\n",
    "print(df_2_1['last_funding_gap'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876b9272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция перевода дней по столбцу 'last_funding_gap' в категории (30)\n",
    "def category_lastgap_func(x):\n",
    "    for i in range(0, 30):\n",
    "        if x > i * 365 and x < i * 365 + 365:            \n",
    "            return i\n",
    "    return 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197aaf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Переведем дни по столбцу df_1_1 'last_funding_gap' в категории\n",
    "df_1_1['category_lastgap'] = df_1_1['last_funding_gap'].apply(category_lastgap_func)\n",
    "df_2_1['category_lastgap'] = df_2_1['last_funding_gap'].apply(category_lastgap_func)\n",
    "df_1_1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c4a4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcb9b19",
   "metadata": {},
   "source": [
    "Выводы по шагу \"Разработка новых синтетических признаков\":\n",
    "\n",
    "1. Для поиска наиболее оптимального набора признаков в таблицы добавлены новые столбцы.\n",
    "2. Столбец 'category_funding_log'\n",
    "3. Столбец 'category_lifetime'\n",
    "4. Столбец 'category_location'\n",
    "5. Столбец 'category_firstgap'\n",
    "6. Столбец 'category_lastgap'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8bdff1",
   "metadata": {},
   "source": [
    "Шаг 5. Корреляционный анализ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b833c170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Имеем следующие признаки, которые можно комбинировать для получения лучшей модели:\n",
    "columns = ['name', 'category_list', 'funding_total_usd', 'status', 'country_code', 'funding_rounds', 'founded_at', 'closed_at'] \n",
    "new_columns = ['lifetime', 'post_days', 'funding_total_log', 'first_funding_gap', 'last_funding_gap']\n",
    "cat_columns = ['category_funding_log', 'category_lifetime', 'category_location', 'category_firstgap', 'category_lastgap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19d61bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим финальную копию обучающего датасета\n",
    "df_train = df_1_1[['lifetime', 'post_days', 'status']]\n",
    "df_train = df_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd98029a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим финальную копию целевого датасета\n",
    "df_test = df_2_1[['name', 'post_days', 'lifetime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacd0a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# В столбце 'status' df_train применим 1 и 0\n",
    "df_train['status'] = df_train['status'].apply(lambda x: 0 if x == 'operating' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bde9985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выберем численные столбцы для анализа\n",
    "num_columns = ['lifetime', 'post_days', 'status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626a80bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычислим матрицу корреляции с использованием phik\n",
    "corr_matrix = df_train.phik_matrix(interval_cols=num_columns)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Phi_K Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f78e16",
   "metadata": {},
   "source": [
    "Выводы по шагу \"Разработка новых синтетических признаков\":\n",
    "\n",
    "1. В поисках наиболее оптимального результата было составлено около 100 наборов входных признаков.\n",
    "2. Самый лучший результат дал набор из признаков 'lifetime' и 'post_days'.\n",
    "3. Мультикорреляция между этими признаками отсутствует."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b26e78",
   "metadata": {},
   "source": [
    "Шаг 6 и 7. Выбор и обучение моделей. Получение результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debbd773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучающий датасет готов\n",
    "df_train.reset_index(drop=True)\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963e8a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c495201e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестовый датасет готов\n",
    "#df_test.reset_index(drop=True)\n",
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5c201d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef4cfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Соберем входные признаки по типам:\n",
    "num_columns = ['lifetime', 'post_days']\n",
    "ohe_columns = []\n",
    "ord_columns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19799ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим тренировочную и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_train.drop(['status'], axis=1),\n",
    "    df_train['status'],\n",
    "    test_size = 0.25, \n",
    "    random_state = RANDOM_STATE,\n",
    "    stratify = df_train['status']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb9a4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сбалансируем доли успешных и закрытых стартапов\n",
    "sm = SMOTE(random_state=42, k_neighbors=5)\n",
    "X_train_resample, y_train_resample = sm.fit_resample(X_train, y_train)\n",
    "y_train_resample.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca3aaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция построения пайплайн на основе модели линейной регрессии. Возвращает y_test_pred, y_test, f1_test.\n",
    "def pipeline_func(X_train, X_test, y_train, y_test):\n",
    "    ohe_pipe = Pipeline(\n",
    "        [\n",
    "            (\n",
    "                'ohe',                                                              \n",
    "                OneHotEncoder(                                                      \n",
    "                    drop=None, \n",
    "                    handle_unknown='ignore',               \n",
    "                    categories='auto')        \n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    # Соберем пайплайн подготовки данных\n",
    "    data_preprocessor = ColumnTransformer(\n",
    "        [\n",
    "            ('ohe', ohe_pipe, ohe_columns),\n",
    "            ('num', MinMaxScaler(), num_columns)                                     \n",
    "        ]     \n",
    "    )\n",
    "    # Соберем итоговый пайплайн\n",
    "    pipe_final= Pipeline(\n",
    "        [\n",
    "            ('preprocessor', data_preprocessor),\n",
    "            ('model', RandomForestClassifier(random_state=RANDOM_STATE))         \n",
    "        ]\n",
    "    )\n",
    "    # Составим гиперпараметры для моделей\n",
    "    param_distributions = [\n",
    "        # словарь для модели KNeighborsClassifier() \n",
    "        {        \n",
    "            'model': [KNeighborsClassifier()],\n",
    "            # указываем гиперпараметр модели\n",
    "            'model__n_neighbors': range(1, 20),\n",
    "            # указываем список методов масштабирования\n",
    "            'preprocessor__num': [StandardScaler(), MinMaxScaler()]   \n",
    "        },\n",
    "        # словарь для модели RandomForestClassifier()\n",
    "        {\n",
    "            'model': [RandomForestClassifier(random_state=RANDOM_STATE)],\n",
    "            'model__max_features': range(2, 6),\n",
    "            'model__max_depth': range(2, 12),\n",
    "            'preprocessor__num': [StandardScaler(), MinMaxScaler(), 'passthrough']  \n",
    "        },\n",
    "        # словарь для модели LogisticRegression()\n",
    "        {\n",
    "            'model': [LogisticRegression(random_state=RANDOM_STATE, \n",
    "                solver='liblinear', \n",
    "                penalty='l1')],\n",
    "            'model__C': range(1, 4),\n",
    "            'preprocessor__num': [StandardScaler(), MinMaxScaler(), 'passthrough']  \n",
    "        } \n",
    "    ]    \n",
    "    # Настроим поиск по гиперпараметрам\n",
    "    randomized_search = RandomizedSearchCV(\n",
    "        pipe_final,\n",
    "        param_distributions=param_distributions, \n",
    "        scoring='f1',\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_iter=10,\n",
    "        verbose=10,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    # Обучим модель\n",
    "    randomized_search.fit(X_train, y_train)\n",
    "    # Выведем параметры лучшей модели\n",
    "    print('Лучшая модель и её параметры:\\n\\n', randomized_search.best_estimator_) \n",
    "    print('Метрика лучшей модели на кросс-валидации:', randomized_search.best_score_)\n",
    "    # Применим лучшую модель к тренировочной выборке\n",
    "    y_train_pred = randomized_search.predict(X_train)\n",
    "    print(f'Метрика F1 на тренировочной выборке: {round(f1_score(y_train, y_train_pred), 2)}')    \n",
    "    # Применим лучшую модель к тестовой выборке тренировочного датасета\n",
    "    y_test_pred = randomized_search.predict(X_test)\n",
    "    score = round(f1_score(y_test, y_test_pred, pos_label=1), 2)\n",
    "    print(f'Метрика F1 на тестовой выборке: {score}')\n",
    "    y_test_predict_proba = randomized_search.predict_proba\n",
    "    # Применим лучшую модель к тестовому датасету\n",
    "    y_test_pred_1 = randomized_search.predict(df_test)\n",
    "    \n",
    "    return y_test_pred, y_test, score, y_test_pred_1, y_test_predict_proba\n",
    "\n",
    "pred_result = pipeline_func(X_train_resample, X_test, y_train_resample, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7ad2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_result[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb83a3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразуем list в series\n",
    "pred_series = pd.Series(pred_result[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9186478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим итоговый датасет с названиями и предсказанными статусами стартапов\n",
    "result = pd.DataFrame()\n",
    "result['name'] = df_2['name']\n",
    "result['status'] = pred_series\n",
    "result['status'] = result['status'].apply(lambda x: 'operating' if x == 0 else 'closed')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5695719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проконтролируем результаты предсказания\n",
    "result['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac50630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выгрузим в файл\n",
    "result.to_csv('output_100.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81eff460",
   "metadata": {},
   "source": [
    "Выводы по шагу \"Выбор и обучение моделей. Получение результат.\":\n",
    "\n",
    "1. Самой успешной оказалась модель RandomForestClassifier(max_depth=7, max_features=3, random_state=42).\n",
    "2. Самый лучший результат метрики F1 = 1.00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9b1950",
   "metadata": {},
   "source": [
    "Шаг 8. Проверка важность признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbd9310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получим выборку из 1000 рандомных строк df_1\n",
    "df_shap2 = df_train.sample(1000)\n",
    "df_shap2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f02d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверим распределение статусов\n",
    "df_shap2['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54853db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим тренировочную и тестовую shap-выборки\n",
    "X_train_shap2, X_test_shap2, y_train_shap2, y_test_shap2 = train_test_split(\n",
    "    df_shap2.drop(['status'], axis=1),\n",
    "    df_shap2['status'],\n",
    "    test_size = TEST_SIZE, \n",
    "    random_state = RANDOM_STATE,\n",
    "    stratify = df_shap2['status']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08affd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применим пайплайн!функцию к shap-выборкам\n",
    "shap2_result = pipeline_func(X_train_shap2, X_test_shap2, y_train_shap2, y_test_shap2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfe5c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проведем SHAP-анализ важности признаков\n",
    "explainer = shap.KernelExplainer(shap2_result[4], X_test_shap2, keep_index=True)\n",
    "shap_values2 = explainer(X_test_shap2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f1d06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Помотрим размеры таблицы результатов SHAP-анализа\n",
    "shap_values2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b5fcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для построения графика возьмем экземпляр с одним измерением\n",
    "shap_values2 = shap_values2[:, :, 1]\n",
    "shap_values2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3097373c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализируем вклад каждого признака в классификацию всех наблюдений\n",
    "shap.plots.beeswarm(shap_values2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151c6926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализируем индивидуальные SHAP-значения отдельного наблюдения\n",
    "shap.plots.waterfall(shap_values2[5])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a626826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализируем общий вклад признаков в прогнозы модели\n",
    "shap.plots.bar(shap_values2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28643db6",
   "metadata": {},
   "source": [
    "Выводы по шагу \"Проверка важность признаков\":\n",
    "\n",
    "1. Наибольший вклад в обученик и прогнозирование вносит признак 'post_days'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aba646",
   "metadata": {},
   "source": [
    "Шаг 8. Выводы и рекомендации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a75be9b",
   "metadata": {},
   "source": [
    "Выводы:\n",
    "\n",
    "1. Были использованы два источника: обучающая база данных имеет 52514 записей и целевая тестовая база - 13125 записей. \n",
    "2. Источники имеют неодинаковые наборы столбцов. Обучающая база содержит столбец с целевым признаком и дополнительный столбец 'closed_at' для явного указания стартапов, закрытых до 2018-01-01. База данных для предсказаний содержит столбец 'lifetime'. отсутствующий в обучающей базе.\n",
    "3. Источники практически не имут дубликатов, но имеют многочисленные пропуски в данных. Дубликаты удалены. Пропуски заполнены.\n",
    "4. В категориальных столбцах обеих таблиц пропуски заменены значением 'Unknown'. Это сделано чтобы в обучении участвовало как можно больше записей.\n",
    "5. В солбце 'funding_total_usd' пропуски заменены медианными значениями.\n",
    "6. В df_1_1 удалены записи с выбросами по солбцу 'funding_total_usd'. Предел финансирования выбран в 200 млн. USD.\n",
    "7. После предварительной обработки таблица df_1_1 содержит 52016 записей, таблица df_2_1 содержит 13125 записей.\n",
    "8. Для соответствия с df_2_1 в таблицу df_1_1 добавлен столбец 'lifetime'.\n",
    "9. В обе таблицы добавлен столбец 'post_days' - количество дней с закрытия стартапа.\n",
    "10. Чтобы учесть логарифмическое характер распределения сумм финансирования стартапов, данные по столбцу 'funding_total_usd' обращены в логарифмы.\n",
    "11. Построены диаграммы распределения действующих и закрытых стартапов, а также диаграммы распределения долей закрытых стартапов в зависимости от различных факторов.\n",
    "12. Выяснилось, что закрытые статапы в наибольшей доле финансировались на суммы менее 100000 долларов.\n",
    "13. За рассматриваемый период чаще всего стартапы закрывались в странах третьего мира типа Сомали, Майотта, Грузии, Пуэрто-Рико и в России.\n",
    "14. Закрытые стартапы чаще всего имели не более одного раунда финансирования.\n",
    "15. Закрытые стартапы чаще всего имели время жизни не более трех лет.\n",
    "16. Введены новые входные признаки: 'category_funding_log' - логарифм от суммы финансирования стартапа, 'category_lifetime' - категория по времени жизни стартапа, 'category_location' - категория от страны-местоположения стартапа, 'category_firstgap' - категория от промежутка в днях между открытием стартапа и первым раундом финансирования, 'category_lastgap' - категория от промежутка в днях между первым  и последним раундоми финансирования.\n",
    "17. В поисках наиболее оптимального результата для обучения модели МО было использовано около 100 наборов входных признаков.\n",
    "18. Мультикорреляция между признаками отсутствовала.\n",
    "19. Самый лучший результат дал набор из признаков 'lifetime' и 'post_days'.\n",
    "20. Самой успешной оказалась модель RandomForestClassifier(max_depth=7, max_features=3, random_state=42).\n",
    "21. Самый лучший результат имеет метрику F1 = 1.00\n",
    "22. Каждый набор признаков исследовался на важность. \n",
    "23. В самом успешном случае наибольший вклад в обучение и прогнозирование внес признак 'post_days'.\n",
    "\n",
    "Рекомендации:\n",
    "\n",
    "1. Как показал исследовательский анализ данных, при прочих равных условиях, наиболее значительное влияние на успешность стартапа имеют систематические финасовые вложения на протяжении не менее трех лет. \n",
    "2. Общая сумма финансовых вложений желательно должна составлять не менее 100 тысяч долларов. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
